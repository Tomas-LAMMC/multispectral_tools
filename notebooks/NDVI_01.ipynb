{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275eb08f-5038-4948-82db-6340470018bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099348e9-bc87-4459-b1a1-4c64a42a312f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import micasense.image as image\n",
    "import micasense.capture as capture\n",
    "import os, glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e427a2-5d5f-40e6-a5b8-db5801137c02",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the base path to your data\n",
    "imagePath = Path(\"../data/tabakas_hand\")\n",
    "\n",
    "# Identify the survey (actual) images\n",
    "# Replace 'IMG_0015_*' with the prefix for your specific survey capture\n",
    "imageNames = list(imagePath.glob('IMG_0015_*.tif'))\n",
    "imageNames = [x.as_posix() for x in imageNames]\n",
    "\n",
    "# Identify the calibration panel images\n",
    "# Replace 'IMG_0002_*' with the prefix for your panel capture\n",
    "panelNames = list(imagePath.glob('IMG_0002_*.tif'))\n",
    "panelNames = [x.as_posix() for x in panelNames]\n",
    "\n",
    "print(f\"Survey images found ({len(imageNames)}):\")\n",
    "for name in imageNames: print(f\" - {os.path.basename(name)}\")\n",
    "\n",
    "print(f\"\\nPanel images found ({len(panelNames)}):\")\n",
    "for name in panelNames: print(f\" - {os.path.basename(name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd08030e-fd8e-4ea2-8cea-98a1b5651016",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the survey images into a Capture object\n",
    "survey_capture = capture.Capture.from_filelist(imageNames)\n",
    "img_type = \"radiance\"\n",
    "\n",
    "# Load the calibration panel images into a Capture object\n",
    "panel_capture = capture.Capture.from_filelist(panelNames)\n",
    "#thecapture = capture.Capture.from_filelist(imageNames)\n",
    "# Verification\n",
    "print(f\"Survey Capture ID: {survey_capture.uuid} ({survey_capture.camera_model})\")\n",
    "print(f\"Panel Capture ID: {panel_capture.uuid} ({panel_capture.camera_model})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb3c708-5920-45cf-ae7a-0b04ace7432b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##  <p style=\"color:blue; font-size:18px\">Foto uŽkrautos, toliau skaičiuosim atspindžius</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6825860b-7b58-4e55-bbe9-2d7885fc5a27",
   "metadata": {},
   "source": [
    "# Calculate Irradiance (from Panel)\n",
    "##  <p style=\"color:green; font-size:18px\">\"Irradiance\" duomenys iš kalibracinės paneles. VIsų šešių nuotrauko atspindžio energija.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e57fd-17ef-49dd-9ee1-291eaa1c3ca3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the sunlight intensity (irradiance) using the panel capture\n",
    "irradiance_list = panel_capture.panel_irradiance()\n",
    "\n",
    "# Verify the numbers\n",
    "print(f\"Irradiance values (6 bands): {irradiance_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a85f10-b683-406a-afcd-d264decdbd55",
   "metadata": {},
   "source": [
    "##  <p style=\"color:green; font-size:18px\">Tiriamos nuotraukos kompensacija pgl. kalibracinės panleles atspinėtą energiją.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52464e2a-a6c5-41e1-85c5-b7f429047033",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Use the panel numbers to calibrate the survey images\n",
    "survey_capture.compute_reflectance(irradiance_list)\n",
    "\n",
    "print(\"Reflectance computed for all survey bands.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462f752-196c-41c6-b689-d9b09fb3cd48",
   "metadata": {},
   "source": [
    "##  <p style=\"color:blue; font-size:18px\">Patikrinimas. Keleto centrinių, nuotraukos pixelių, atspindžio skaitinės vertės prieš ir po kompensacijos</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dff4bb-aa80-477d-ba87-66e7c25ec171",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select the Red band (index 2)\n",
    "img = survey_capture.images[2]\n",
    "\n",
    "# Get a 3x3 patch from the center\n",
    "radiance_data = img.undistorted_radiance()\n",
    "reflectance_data = img.reflectance()\n",
    "cy, cx = radiance_data.shape[0] // 2, radiance_data.shape[1] // 2\n",
    "\n",
    "print(\"--- Radiance (Raw Power) ---\")\n",
    "print(radiance_data[cy-1:cy+2, cx-1:cx+2])\n",
    "\n",
    "print(\"\\n--- Calibrated Reflectance (0-1 Scale) ---\")\n",
    "print(np.round(reflectance_data[cy-1:cy+2, cx-1:cx+2], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d99404-d7e4-414b-85a8-58dbe35c7cec",
   "metadata": {},
   "source": [
    "##  <p style=\"color:blue; font-size:18px\">Patikrinimas. Visualinis nuotraukų palyginimas</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cdbdb8-a60e-4d5f-adb2-80f5ca0220fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Get the Green band\n",
    "green_band_idx = 1\n",
    "img = survey_capture.images[green_band_idx]\n",
    "\n",
    "# 2. Get the two data versions\n",
    "# 'undistorted_radiance' is the raw power (the 0.29... values)\n",
    "# 'reflectance' is the calibrated value (the 0.22... values)\n",
    "before_data = img.undistorted_radiance()\n",
    "after_data = img.reflectance()\n",
    "\n",
    "# 3. Plot side-by-side with a FIXED scale (0.0 to 1.0)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Before Calibration\n",
    "im0 = axes[0].imshow(before_data, vmin=0, vmax=1, cmap='gray')\n",
    "axes[0].set_title(f\"Green Band: BEFORE (Radiance)\\nValue ~0.29\")\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "# After Calibration\n",
    "im1 = axes[1].imshow(after_data, vmin=0, vmax=1, cmap='gray')\n",
    "axes[1].set_title(f\"Green Band: AFTER (Reflectance)\\nValue ~0.22\")\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db14872d-b55b-4273-b74d-bdb93673270f",
   "metadata": {},
   "source": [
    "#  <p style=\"color:blue; font-size:18px\">Foto perskaičiuotos į atspindžius ir kompensuotos pgl kalibracijos plokštelę</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ca934-be27-492d-af3a-34d071fc8f42",
   "metadata": {},
   "source": [
    "## <p style=\"color:green; font-size:16px\">Pirminės matricų(fotografijų) prasislinkimo vertės dėl kameros konstrucijos, šeši skirtingi lešiai, truputį skirtingos jų vietos, taigi visos nuotraukos iš skirtingo taškos, \"prasislinkę\"</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7bced-097b-4fb3-96b0-9972095305d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get initial alignment transformations (warp matrices) from the camera's metadata\n",
    "warp_matrices = survey_capture.get_warp_matrices()\n",
    "\n",
    "print(f\"Factory warp matrices loaded for {len(warp_matrices)} bands.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126871c-33c8-4549-898a-c4fc8928be69",
   "metadata": {},
   "source": [
    "## Nuotraukų sulygiavims pgl. panchromatinę(didžiausią) nuotrauką"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed8f8e54-d7ea-44ea-a814-e598a302805b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Get dimensions from the Panchromatic master (Band 5)\n",
    "h_m, w_m = survey_capture.images[5].undistorted_radiance().shape\n",
    "\n",
    "# 2. Stretch all bands and plot\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, img_obj in enumerate(survey_capture.images):\n",
    "    img = img_obj.undistorted_radiance()\n",
    "    \n",
    "    # Resize if dimensions don't match\n",
    "    if img.shape != (h_m, w_m):\n",
    "        img = cv2.resize(img, (w_m, h_m), interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    # Simple percentile stretch for visibility\n",
    "    p2, p98 = np.percentile(img, (2, 98))\n",
    "    img_viz = np.clip((img - p2) / (p98 - p2), 0, 1)\n",
    "    \n",
    "    axes[i].imshow(img_viz, cmap='gray')\n",
    "    axes[i].set_title(f\"Band {i} ({img_obj.band_name})\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee47726-a1e8-4f3c-b087-c5e0bf3798aa",
   "metadata": {},
   "source": [
    "### PIrma sustumdom nuotraukas pgl. iš akies nustatytas koordinates, tada praleidžiam matematinį algoritmą SIFT tikslesnem sulygiavimui, jei iškart mėginsim SIFT visų pirma užtruks, antrą jei perstumimai didelis negausim jokio rezultato."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d106f2e3-a6c6-4cd4-969d-be334fa657fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "SIFT veikiantis algoritmas su manual pre alignment\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def align_sift(img_target, img_ref, band_idx):\n",
    "    print(f\"Fine-tuning Band {band_idx} with SIFT...\")\n",
    "    ref = cv2.normalize(img_ref, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "    tgt = cv2.normalize(img_target, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "    \n",
    "    sift = cv2.SIFT_create(nfeatures=2000)\n",
    "    kp1, des1 = sift.detectAndCompute(ref, None)\n",
    "    kp2, des2 = sift.detectAndCompute(tgt, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    good = [m for m, n in matches if m.distance < 0.7 * n.distance]\n",
    "    \n",
    "    if len(good) > 15:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        M, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "        print(f\"  --> Success: Found {len(good)} matches for Band {band_idx}\")\n",
    "        return M\n",
    "    else:\n",
    "        print(f\"  --> Failed: Not enough matches for Band {band_idx}. Using manual only.\")\n",
    "        return np.eye(3)\n",
    "\n",
    "# 1. Initialize Matrices\n",
    "pre_matrices = [np.eye(3, dtype=np.float32) for _ in range(6)]\n",
    "pre_matrices[1][0,2], pre_matrices[1][1,2] = 70.0, -25.0\n",
    "pre_matrices[3][0,2], pre_matrices[3][1,2] = 10.0, 40.0\n",
    "pre_matrices[0][0,2], pre_matrices[0][1,2] = -70.0, 80.0\n",
    "pre_matrices[2][0,2], pre_matrices[2][1,2] = 70.0, -40.0\n",
    "pre_matrices[4][0,2], pre_matrices[4][1,2] = 10.0, -40.0\n",
    "\n",
    "final_aligned = [None] * 6\n",
    "ref_img = survey_capture.images[5].undistorted_radiance()\n",
    "h, w = ref_img.shape\n",
    "\n",
    "# 2. Loop through and align\n",
    "for i in range(6):\n",
    "    img = cv2.resize(survey_capture.images[i].undistorted_radiance(), (w, h))\n",
    "    if i == 5:\n",
    "        final_aligned[5] = ref_img\n",
    "        print(\"Band 5 is Anchor (Skipping SIFT)\")\n",
    "        continue\n",
    "        \n",
    "    pre_warped = cv2.warpPerspective(img, pre_matrices[i], (w, h), flags=cv2.WARP_INVERSE_MAP)\n",
    "    m_fine = align_sift(pre_warped, ref_img, i)\n",
    "    m_total = m_fine @ np.linalg.inv(pre_matrices[i])\n",
    "    result = cv2.warpPerspective(img, m_total, (w, h), flags=cv2.INTER_LANCZOS4)\n",
    "    final_aligned[i] = result\n",
    "\n",
    "# 3. Plot Result (Clipped to prevent warnings)\n",
    "rgb = np.stack([final_aligned[2], final_aligned[1], final_aligned[0]], axis=2)\n",
    "rgb_display = np.clip(rgb / np.percentile(rgb, 98), 0, 1) # Added clipping here\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(rgb_display)\n",
    "plt.title(\"Final Alignment: Manual Pre-Correction + SIFT Fine-Tuning\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91a0c2f0-10c4-4673-a399-281b655e3a40",
   "metadata": {},
   "source": [
    "# from micasense.imageutils import brovey_pan_sharpen,radiometric_pan_sharpen\n",
    "from skimage.transform import ProjectiveTransform\n",
    "import time\n",
    "\n",
    "    # set to True if you'd like to ignore existing warp matrices and create new ones\n",
    "regenerate = True\n",
    "st = time.time()\n",
    "\n",
    "print(\"Generating new warp matrices...\")\n",
    "#original        warp_matrices_SIFT = thecapture.SIFT_align_capture(min_matches = 10)\n",
    "warp_matrices_SIFT = survey_capture.SIFT_align_capture(\n",
    "        ref=5, \n",
    "        min_matches=15, \n",
    "        err_red=500.0, \n",
    "        err_blue=500.0,\n",
    "        verbose=1\n",
    "        )\n",
    "        \n",
    "sharpened_stack, upsampled = survey_capture.radiometric_pan_sharpened_aligned_capture(warp_matrices=warp_matrices_SIFT, irradiance_list=irradiance_list, img_type=img_type)\n",
    "    \n",
    "# we can also use the Rig Relatives from the image metadata to do a quick, rudimentary alignment \n",
    "#     warp_matrices0=thecapture.get_warp_matrices(ref_index=5)\n",
    "#     sharpened_stack,upsampled = radiometric_pan_sharpen(thecapture,warp_matrices=warp_matrices0)\n",
    "\n",
    "print(\"Pansharpened shape:\", sharpened_stack.shape)\n",
    "print(\"Upsampled shape:\", upsampled.shape)\n",
    "# re-assign to im_aligned to match rest of code \n",
    "im_aligned = upsampled\n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print('Alignment and pan-sharpening time:', int(elapsed_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3fc45-faba-486c-9d5b-1f25b7114695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#veikiantis greitas scriptas su rankiniu budu nustatytais ir ivestais lygiavimo koordinaciu pataisymais\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def align_sift(img_target, img_ref, band_idx):\n",
    "    print(f\"Fine-tuning Band {band_idx} with SIFT...\")\n",
    "    ref = cv2.normalize(img_ref, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "    tgt = cv2.normalize(img_target, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "    \n",
    "    sift = cv2.SIFT_create(nfeatures=2000)\n",
    "    kp1, des1 = sift.detectAndCompute(ref, None)\n",
    "    kp2, des2 = sift.detectAndCompute(tgt, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    good = [m for m, n in matches if m.distance < 0.7 * n.distance]\n",
    "    \n",
    "    if len(good) > 15:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        M, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "        print(f\"  --> Success: {len(good)} matches for Band {band_idx}\")\n",
    "        return M\n",
    "    print(f\"  --> Failed: Using manual only for Band {band_idx}.\")\n",
    "    return np.eye(3)\n",
    "\n",
    "# 1. Setup\n",
    "pre_matrices = [np.eye(3, dtype=np.float32) for _ in range(6)]\n",
    "pre_matrices[1][0,2], pre_matrices[1][1,2] = 70.0, -25.0\n",
    "pre_matrices[3][0,2], pre_matrices[3][1,2] = 10.0, 40.0\n",
    "pre_matrices[0][0,2], pre_matrices[0][1,2] = -70.0, 80.0\n",
    "pre_matrices[2][0,2], pre_matrices[2][1,2] = 70.0, -40.0\n",
    "pre_matrices[4][0,2], pre_matrices[4][1,2] = 10.0, -40.0\n",
    "\n",
    "final_aligned = [None] * 6\n",
    "manual_only = [None] * 6  # DEFINED HERE\n",
    "ref_img = survey_capture.images[5].undistorted_radiance()\n",
    "h, w = ref_img.shape\n",
    "\n",
    "# 2. Process\n",
    "for i in range(6):\n",
    "    img = cv2.resize(survey_capture.images[i].undistorted_radiance(), (w, h))\n",
    "    \n",
    "    # Apply manual shift and store it\n",
    "    pre_warped = cv2.warpPerspective(img, pre_matrices[i], (w, h), flags=cv2.WARP_INVERSE_MAP)\n",
    "    manual_only[i] = pre_warped\n",
    "    \n",
    "    if i == 5:\n",
    "        final_aligned[5] = ref_img\n",
    "        continue\n",
    "        \n",
    "    m_fine = align_sift(pre_warped, ref_img, i)\n",
    "    m_total = m_fine @ np.linalg.inv(pre_matrices[i])\n",
    "    final_aligned[i] = cv2.warpPerspective(img, m_total, (w, h), flags=cv2.INTER_LANCZOS4)\n",
    "\n",
    "# 3. Plot Comparison\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Left: Manual\n",
    "manual_rgb = np.stack([manual_only[2], manual_only[1], manual_only[0]], axis=2)\n",
    "m_disp = np.clip(manual_rgb / np.percentile(manual_rgb, 98), 0, 1)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(m_disp)\n",
    "plt.title(\"Before SIFT (Manual Only)\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Right: Final\n",
    "final_rgb = np.stack([final_aligned[2], final_aligned[1], final_aligned[0]], axis=2)\n",
    "f_disp = np.clip(final_rgb / np.percentile(final_rgb, 98), 0, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(f_disp)\n",
    "plt.title(\"After SIFT (Fine-tuned)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.imsave(\"Before_SIFT_Manual_Only.png\", m_disp)\n",
    "plt.imsave(\"After_SIFT_Fine_tuned.png\", f_disp)\n",
    "\n",
    "print(\"Images saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da40c7e-b4fe-4b53-8524-0c3c31a03fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Manually set the rig relatives in the capture object\n",
    "# This replaces the factory settings with your research-optimized ones\n",
    "for i in range(5):\n",
    "    survey_capture.images[i].meta.set_calibration_rig_relatives(pre_matrices[i])\n",
    "\n",
    "# 2. Now run SIFT\n",
    "# It will now use your pre_matrices as the baseline for 'warp_matrices_calibrated'\n",
    "warp_matrices_SIFT = survey_capture.SIFT_align_capture(ref=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa6d125-0bd6-4ace-8e76-fa5e8ba2cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import micasense.imageutils as imageutils\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "# 1. Use your manual matrices as the starting point\n",
    "# (Assuming you still have 'pre_matrices' from our previous steps)\n",
    "initial_matrices = [m.astype(np.float32) for m in pre_matrices]\n",
    "\n",
    "# 2. Run SIFT, but tell it to START from your manual alignment\n",
    "# This helps SIFT not get \"lost\" in the background\n",
    "#warp_matrices_SIFT = survey_capture.SIFT_align_capture(\n",
    "#    ref=5, \n",
    "#    min_matches=20,     # Increased for better accuracy\n",
    "#    err_red=200.0,      # Tightened error threshold\n",
    "#    err_blue=200.0,\n",
    "#    verbose=1\n",
    "#)\n",
    "\n",
    "warp_matrices_SIFT = survey_capture.SIFT_align_capture(\n",
    "    ref=5, \n",
    "    min_matches=20,\n",
    "    err_red=200.0,\n",
    "    err_blue=200.0,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Apply the sharpening using the refined matrices\n",
    "sharpened_stack, upsampled = survey_capture.radiometric_pan_sharpened_aligned_capture(\n",
    "    warp_matrices=warp_matrices_SIFT, \n",
    "    irradiance_list=irradiance_list, \n",
    "    img_type='radiance'\n",
    ")\n",
    "\n",
    "print(\"Pansharpened shape:\", sharpened_stack.shape)\n",
    "print(\"Upsampled shape:\", upsampled.shape)\n",
    "# re-assign to im_aligned to match rest of code \n",
    "im_aligned = upsampled\n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print('Alignment and pan-sharpening time:', int(elapsed_time), 'seconds')\n",
    "\n",
    "# 4. Extract RGB from upsampled (Indices 2, 1, 0) and Normalize\n",
    "rgb_sharp = np.stack([upsampled[:,:,2], upsampled[:,:,1], upsampled[:,:,0]], axis=2)\n",
    "\n",
    "# High-quality stretch for saving\n",
    "rgb_sharp_disp = np.clip(rgb_sharp / np.percentile(rgb_sharp, 98), 0, 1)\n",
    "\n",
    "# 5. Save the file\n",
    "plt.imsave(\"micasense_alignment.png\", rgb_sharp_disp)\n",
    "\n",
    "print(\"Micasense pan-sharpened result saved as micasense_alignment.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b517142a-5147-4437-a6fe-39c778b587d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figsize=(30,23) # use this size for full-image-resolution display\n",
    "figsize=(16,13)   # use this size for export-sized display\n",
    "\n",
    "rgb_band_indices = [survey_capture.band_names_lower().index('red'),\n",
    "                    survey_capture.band_names_lower().index('green'),\n",
    "                    survey_capture.band_names_lower().index('blue')]\n",
    "cir_band_indices = [survey_capture.band_names_lower().index('nir'),\n",
    "                    survey_capture.band_names_lower().index('red'),\n",
    "                    survey_capture.band_names_lower().index('green')]\n",
    "\n",
    "# Create normalized stacks for viewing\n",
    "im_display = np.zeros((im_aligned.shape[0],im_aligned.shape[1],im_aligned.shape[2]), dtype=np.float32)\n",
    "im_min = np.percentile(im_aligned[:,:,rgb_band_indices].flatten(), 0.5)  # modify these percentiles to adjust contrast\n",
    "im_max = np.percentile(im_aligned[:,:,rgb_band_indices].flatten(), 99.5)  # for many images, 0.5 and 99.5 are good values\n",
    "\n",
    "\n",
    "im_display_sharp = np.zeros((sharpened_stack.shape[0],sharpened_stack.shape[1],sharpened_stack.shape[2]), dtype=np.float32 )\n",
    "im_min_sharp = np.percentile(sharpened_stack[:,:,rgb_band_indices].flatten(), 0.5)  # modify these percentiles to adjust contrast\n",
    "im_max_sharp = np.percentile(sharpened_stack[:,:,rgb_band_indices].flatten(), 99.5)  # for many images, 0.5 and 99.5 are good values\n",
    "\n",
    "\n",
    "# for rgb true color, we use the same min and max scaling across the 3 bands to \n",
    "# maintain the \"white balance\" of the calibrated image\n",
    "for i in rgb_band_indices:\n",
    "    im_display[:,:,i] =  imageutils.normalize(im_aligned[:,:,i], im_min, im_max)\n",
    "\n",
    "    im_display_sharp[:,:,i] = imageutils.normalize(sharpened_stack[:,:,i], im_min_sharp, im_max_sharp)\n",
    "\n",
    "rgb = im_display[:,:,rgb_band_indices]\n",
    "\n",
    "\n",
    "rgb_sharp = im_display_sharp[:,:,rgb_band_indices]\n",
    "\n",
    "nir_band = survey_capture.band_names_lower().index('nir')\n",
    "red_band = survey_capture.band_names_lower().index('red')\n",
    "\n",
    "ndvi = (im_aligned[:,:,nir_band] - im_aligned[:,:,red_band]) / (im_aligned[:,:,nir_band] + im_aligned[:,:,red_band])\n",
    "\n",
    "# for cir false color imagery, we normalize the NIR,R,G bands within themselves, which provides\n",
    "# the classical CIR rendering where plants are red and soil takes on a blue tint\n",
    "for i in cir_band_indices:\n",
    "    im_display[:,:,i] =  imageutils.normalize(im_aligned[:,:,i])\n",
    "\n",
    "cir = im_display[:,:,cir_band_indices]\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    #fig, ax1 = plt.subplots(1, 1, figsize=figsize)\n",
    "ax1.set_title(\"Red-Green-Blue Composite\")\n",
    "ax1.imshow(rgb)\n",
    "\n",
    "ax2.set_title(\"Red-Green-Blue Composite (pan-sharpened)\")\n",
    "ax2.imshow(rgb_sharp)\n",
    "\n",
    "fig, (ax3,ax4) = plt.subplots(1, 2, figsize=figsize)\n",
    "ax3.set_title(\"NDVI\")\n",
    "ax3.imshow(ndvi)\n",
    "ax4.set_title(\"Color Infrared (CIR) Composite\")\n",
    "ax4.imshow(cir)\n",
    "\n",
    "# set custom lims if you want to zoom in to image to see more detail \n",
    "# this is useful for comparing upsampled and pan-sharpened stacks \n",
    "# custom_xlim=(1500,2000)\n",
    "# custom_ylim=(2000,1500)\n",
    "# plt.setp([ax1,ax2,ax3,ax4], xlim=custom_xlim, ylim=custom_ylim)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ebd258-5689-48bc-af55-9a3256c2cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Micasense upsampled order is typically [B, G, R, RE, NIR]\n",
    "# We want R(2), G(1), B(0)\n",
    "rgb = np.stack([upsampled[:,:,2], upsampled[:,:,1], upsampled[:,:,0]], axis=2)\n",
    "\n",
    "# Normalize for display\n",
    "rgb_display = np.clip(rgb / np.percentile(rgb, 98), 0, 1)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(rgb_display)\n",
    "plt.title(\"Pan-Sharpened RGB Composite\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06854e-60db-4da4-a81d-9f012835e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIR is index 4, Red is index 2\n",
    "nir = upsampled[:,:,4]\n",
    "red = upsampled[:,:,2]\n",
    "\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    ndvi_sharp = (nir - red) / (nir + red)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(ndvi_sharp, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "plt.colorbar(label='NDVI')\n",
    "plt.title(\"High-Res Pan-Sharpened NDVI\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891ceef-7abe-4b78-8e2f-fcafe2d93329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Enhanced \"Natural\" RGB Plot\n",
    "rgb = np.stack([final_aligned[2], final_aligned[1], final_aligned[0]], axis=2)\n",
    "\n",
    "# A. Histogram Stretch (Individual channel normalization)\n",
    "for i in range(3):\n",
    "    low, high = np.percentile(rgb[:,:,i], (2, 99)) # Ignore bottom 2% and top 1% noise\n",
    "    rgb[:,:,i] = np.clip((rgb[:,:,i] - low) / (high - low), 0, 1)\n",
    "\n",
    "# B. Apply Gamma Correction (typically 0.45 to 0.67 makes it look natural)\n",
    "gamma = 0.6\n",
    "rgb_natural = np.power(rgb, gamma)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(rgb_natural)\n",
    "plt.title(\"Natural Look: Histogram Stretch + Gamma Correction\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
